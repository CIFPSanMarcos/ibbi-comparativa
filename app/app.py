import streamlit as st
import pandas as pd
import plotly.express as px
import requests
import random
import time
import os
import subprocess
from collections import deque
from datetime import datetime, timedelta
from influxdb_client_3 import InfluxDBClient3
from openai import OpenAI

# Ruta base del proyecto (raÃ­z del repositorio)
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))

# Ruta a la carpeta 'data'
DATA_DIR = os.path.join(BASE_DIR, 'data')

LOAD_FROM_CSV = False
if 'DATA_SOURCE' in st.secrets and st.secrets["DATA_SOURCE"] == "csv":
    LOAD_FROM_CSV = True

def get_token():
    tb_url = st.secrets["TB_API_URL"]
    tb_user = st.secrets["TB_USER"]
    tb_pass = st.secrets["TB_PASS"]

    # 1. AutenticaciÃ³n: obtener JWT token
    auth_url = f"{tb_url}/api/auth/login"
    auth_payload = {
        "username": tb_user,
        "password": tb_pass
    }

    auth_response = requests.post(auth_url, json=auth_payload)
    if auth_response.status_code != 200:
        print("âŒ Error al autenticar:", auth_response.text)
        exit()

    jwt_token = auth_response.json().get("token")
    print("ðŸ” Token obtenido correctamente")
    return jwt_token

def prepare_dataframe(df, key, name, start_date, end_date):
    if "timestamp" not in df.columns:
        df = df.rename(columns={"ts": "timestamp"})

    # Convertir timestamp a datetime y extraer la fecha
    df["fecha"] = pd.to_datetime(df["timestamp"]).dt.date

    # Filtrar por rango de fechas
    df = df[(df["fecha"] > start_date) & (df["fecha"] <= end_date)]
    
    # SelecciÃ³n y renombrado de columnas
    df = df[["timestamp", "fecha", key]]
    df = df.rename(columns={key: key_map[key]})
    df["zona"] = name
    return df

def load_data_from_csv(start_date, end_date, src_key):
    print(f"ðŸ”„ Cargando datos desde CSV para el rango {start_date} â†’ {end_date}...")
    df = pd.DataFrame()
    try:
        for name in device_names:
            df_zone = pd.read_csv(os.path.join(DATA_DIR, f"{name}_1h.csv"))
            df_zone = prepare_dataframe(df_zone, src_key, name, start_date, end_date)
            df = pd.concat([df, df_zone], ignore_index=True)

        df = df.sort_values(by=["timestamp", "zona"]).reset_index(drop=True)
        df["timestamp"] = pd.to_datetime(df['timestamp'])
        return df
    except Exception as e:
        st.error(f"Error al cargar los datos: {e}")
        return pd.DataFrame()

def get_latest_data_from_tb(device_id, key):
    url = f"{tb_url}/api/plugins/telemetry/DEVICE/{device_id}/values/timeseries?limit=1&keys={key}"
    headers = {
        "X-Authorization": f"Bearer {token}"
    }
    response = requests.get(url, headers=headers)
    response.raise_for_status()
    data = response.json()
    if key not in data:
        return None
    latest_value = data[key][0]
    return {
        "ts": datetime.fromtimestamp(int(latest_value["ts"]) / 1000),
        "value": float(latest_value["value"])
    }

def get_data_from_tb(device_id, key, start_ts, end_ts):
    url = f"{tb_url}/api/plugins/telemetry/DEVICE/{device_id}/values/timeseries"
    params = {
        "keys": src_key,
        "startTs": start_ts,
        "endTs": end_ts,
        "interval": 3600000,  # 1 hora
        "limit": 24,
        "agg": "AVG"
    }
    headers = {
        "X-Authorization": f"Bearer {token}"
    }
    # Realizar la solicitud a ThingsBoard
    response = requests.get(url, headers=headers, params=params)
    response.raise_for_status()
    data = response.json()
    # Procesar resultados
    if src_key not in data:
        return pd.DataFrame()
    
    valores = [
        {
            "ts": datetime.fromtimestamp(int(item["ts"]) / 1000),
            src_key: float(item["value"])
        }
        for item in data[src_key]
    ]
    return pd.DataFrame(valores)

def load_data_from_tb(date):
    df = pd.DataFrame()
    
    # Rango horario del dÃ­a
    start_ts = int(datetime.combine(date, datetime.min.time()).timestamp() * 1000)
    end_ts = int(datetime.combine(date + timedelta(days=1), datetime.min.time()).timestamp() * 1000)
    try:
        print(f"ðŸ”„ Cargando datos desde ThingsBoard para la fecha {date}...")
        for name, device_id in device_id_map.items():
            latest_data = get_latest_data_from_tb(device_id, src_key)
            last_dt = latest_data["ts"] if latest_data else None
            print(f"Ãšltimo dato de {name} [{device_id}]: {last_dt}")
            df_zone = get_data_from_tb(device_id, src_key, start_ts, end_ts)
            df_zone["zona"] = name
            if not df_zone.empty:
                df_zone = prepare_dataframe(df_zone, src_key, name, date)
                df = pd.concat([df, df_zone], ignore_index=True)

        if not df.empty:
            df = df.sort_values(by=["timestamp", "zona"]).reset_index(drop=True)
        
        return df

    except:
        st.error(f"Error al cargar los datos: {e}")
        return pd.DataFrame()
    
def get_latest_data_from_influx(client, key):
    query = f"""SELECT "{key}", "time", "zona"
        FROM "energia"
        WHERE
        "{key}" IS NOT NULL
        AND "zona" IN ('zonaalta', 'zonabaja', 'zonamedia')
        ORDER BY time DESC
        LIMIT 1 """
    
    table = client.query(query=query, database="ibbi-influxdb", language='sql')

    # Convert to dataframe
    df = table.to_pandas().sort_values(by=["time", "zona"])
    df = df.rename(columns={"time": "timestamp"})
    return df
    
def query_data_from_influx(client, start_date, end_date, key):
    interval = '1 hour'
    # if end_date - start_date <= timedelta(days=1):
    #     interval = '15 minutes'
    
    query = f"""SELECT
        date_bin(INTERVAL '{interval}', time, TIMESTAMP '1970-01-01T00:00:00Z') AS intervalo,
        zona,
        avg({key}) AS {key}
        FROM
        "energia"
        WHERE
        time >= TIMESTAMP '{start_date}'
        AND time <= TIMESTAMP '{end_date}'
        AND {key} IS NOT NULL
        AND zona IN ('zonaalta', 'zonabaja', 'zonamedia')
        GROUP BY
        intervalo, zona
        ORDER BY
        intervalo, zona """
    
    table = client.query(query=query, database="ibbi-influxdb", language='sql')

    # Convert to dataframe
    df = table.to_pandas()
    df = df.rename(columns={"intervalo": "timestamp"})
    df = df.rename(columns={key: key_map[key]})
    df["fecha"] = pd.to_datetime(df["timestamp"]).dt.date

    return df

def load_data_from_influx(start_date, end_date, key):
    # AquÃ­ irÃ­a la lÃ³gica para cargar datos desde InfluxDB
    # Por simplicidad, se deja como un placeholder
    print(f"ðŸ”„ Cargando datos desde InfluxDB para el rango {start_date} â†’ {end_date}...")
    host = st.secrets["INFLUX_HOST"]
    org = st.secrets["INFLUX_ORG"]
    token = st.secrets["INFLUX_TOKEN"]

    client = InfluxDBClient3(host=host, token=token, org=org)
    df = query_data_from_influx(client, start_date, end_date, key)
    if df is not None:
         df = df.sort_values(by=["timestamp", "zona"]).reset_index(drop=True)
         return df
    else:
        st.error("No se pudieron cargar los datos desde InfluxDB.")
        return pd.DataFrame()

# --- ZONAS DISPONIBLES ---
# Mapeo de zonas a nombres
device_map = {
    "zonaalta": "Zona Alta",
    "zonamedia": "Zona Media",
    "zonabaja": "Zona Baja"
}
device_names = device_map.keys()
# Mapeo de zonas a ids
device_id_map = {
    "zonaalta": "3d76ce90-24cc-11f0-93b2-b714401cbb0f",
    "zonamedia": "73d802b0-24cc-11f0-874c-af5d629c6095",
    "zonabaja": "1d6c4040-24cb-11f0-93b2-b714401cbb0f"
}

# --- VARIABLE A VISUALIZAR ---
key_map = {
    "p_total": "energÃ­a",
    "voltaje_LNAvg": "voltaje",
    "intensidad_Avg_total": "intensidad"
}
key_unit_map = {
    "energÃ­a": "kWh",
    "voltaje": "V",
    "intensidad": "A"
}
range_map = {
    "Diario": 1,
    "Semanal": 7,
    "Mensual": 30,
}

now = datetime.now()

today = datetime.now().date()
if LOAD_FROM_CSV:
    today = datetime(2025, 6, 1)
# --- INTERFAZ DE STREAMLIT ---
st.set_page_config(layout="wide")
st.title("iBBi - Comparativa de Consumo EnergÃ©tico")

cola, colb, colc = st.columns([1, 1, 1])
with cola:
    selected_date = st.date_input("Selecciona una fecha", value=today - timedelta(days=1), max_value=today)
with colb:
    # key = st.selectbox("Variable a visualizar", list(key_map.values()), index=0)
    key = "energÃ­a"
    # Mapeo inverso de clave
    src_key = next((k for k, v in key_map.items() if v == key), None)
    
    # SelecciÃ³n de rango de comparaciÃ³n
    range_option = st.selectbox("Rango de comparaciÃ³n", list(range_map.keys()), index=0)
    range_days = range_map[range_option]
    if range_option == "Diario":
        selected_date_vs = selected_date - timedelta(days=1)
    elif range_option == "Semanal":
        selected_date_vs = selected_date - timedelta(weeks=1)
    else:
        selected_date_vs = selected_date - timedelta(days=30)

with colc:
    st.write("")
    
# --- CARGA DE DATOS ---
if LOAD_FROM_CSV:
    # Cargar datos desde CSV
    df_day = load_data_from_csv(selected_date_vs, selected_date, src_key)
    df_vs = load_data_from_csv(selected_date_vs - timedelta(days=range_days), selected_date_vs, src_key)
    if df_day.empty:
        st.warning("No hay datos disponibles para la fecha seleccionada.")
        df_vs = pd.DataFrame()  # Asegurarse de que df_vs estÃ© vacÃ­o si no hay datos
else:
    # Cargar datos desde InluxDB
    df_day = load_data_from_influx(selected_date_vs, selected_date, src_key)
    df_vs = load_data_from_influx(selected_date_vs - timedelta(days=range_days), selected_date_vs, src_key)

# Verificar si los DataFrames estÃ¡n vacÃ­os
if df_day.empty:
    st.warning("No hay datos disponibles para la fecha seleccionada.")
else:
    # Calcular mÃ©tricas
    # st.dataframe(df_day, use_container_width=True)
    df_group = df_day[["timestamp", "zona", key]].set_index("timestamp").groupby("zona").resample("h").mean().reset_index()
    total_value = df_group[key].sum().round()
    avg_value = df_day[key].mean()
    max_value = df_day[key].max()
    hora_max = pd.to_datetime(df_day[df_day[key] == max_value]["timestamp"].values[0]).strftime('%Y-%m-%d %H:%M')
    if not df_vs.empty:
        df_vs_group = df_vs[["timestamp", "zona", key]].set_index("timestamp").groupby("zona").resample("h").mean().reset_index()
        total_value_vs = df_vs_group[key].sum().round()
        delta_total_value = total_value - total_value_vs
        avg_value_vs = df_vs[key].mean()
        delta_avg_value = avg_value - avg_value_vs
        max_value = df_vs[key].max()
    else:
        total_value_vs = 0
        delta_total_value = total_value
        avg_value_vs = 0
        delta_avg_value = avg_value
        max_value = 0
    # Generamos las grÃ¡ficas y mÃ©tricas
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col2:
        # GrÃ¡fico de barras
        df_bar = pd.DataFrame({
            "fecha": [selected_date_vs, selected_date],
            "total": [total_value_vs, total_value]
        })
        fig_bar = px.bar(
            df_bar, 
            x="fecha", 
            y="total",
            color="fecha",
            text_auto=True,
            labels={"total": f"{key} {key_unit_map[key]}"},
            title="Comparativa diaria",
            color_discrete_sequence=px.colors.qualitative.Set2)

        st.plotly_chart(fig_bar, use_container_width=True)
        # MÃ©tricas
        st.markdown("**MÃ©tricas**")
        # Agregar mÃ©tricas por hora
        st.metric("Total", f"{total_value:.2f} {key_unit_map[key]}", f"{delta_total_value:.2f} {key_unit_map[key]}")
        st.metric("Promedio", f"{avg_value:.2f} {key_unit_map[key]}", f"{delta_avg_value:.2f} {key_unit_map[key]}")
        st.metric("MÃ¡ximo", f"{max_value:.2f} {key_unit_map[key]}", f"a las {hora_max}")
        
    with col1:
        # GrÃ¡fico de Ã¡rea
        fig = px.area(
            df_day,
            x="timestamp",
            y=key,
            color="zona",
            markers=True,
            labels={"timestamp": "Hora", key: key.capitalize()},
            title=f"{key.capitalize()} horaria",
            color_discrete_sequence=px.colors.qualitative.Set2
        )
        st.plotly_chart(fig, use_container_width=True)
        # GrÃ¡fico de tarta
        df_sum_pie = df_day.groupby("zona")[key].sum().reset_index()
        df_sum_pie = df_sum_pie.sort_values(by="zona")
        fig_pie = px.pie(
            df_sum_pie, 
            values=key, 
            names="zona",
            category_orders={'zona': df_sum_pie['zona'].tolist()},
            title="DistribuciÃ³n por zona",
            hole=0.4,
            color_discrete_sequence=px.colors.qualitative.Set2
        )
        st.plotly_chart(fig_pie, use_container_width=True)

    with col3:
        st.subheader("Mensaje al alumno")
        openai = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
        # Set a default model
        if "openai_model" not in st.session_state:
            st.session_state["openai_model"] = "gpt-4o-mini"
        
        # Initialize chat history
        if "messages" not in st.session_state:
            st.session_state.messages = deque(maxlen=3)  # Limit history to last 7 messages

        # Display chat messages from history on app rerun
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # definir el nombre del inervalo de comparaciÃ³n
        if range_option == "Diario":
            key_string = f"{key} del dÃ­a"
            date_string = "dÃ­a"
        elif range_option == "Semanal":
            key_string = f"{key} de la semana"
            date_string = "semana"
        else:
            key_string = f"{key} del mes"
            date_string = "mes"
        if not df_vs.empty:
            # Generate user input
            prompt = f"Analiza el consumo de {key_string} {selected_date.strftime('%d/%m/%Y')} y compara con {date_string} anterior. " \
                    f"El consumo total de {date_string} anterior fue de {total_value_vs} kWh y {date_string} seleccionado {total_value} kWh." \
                    f"El consumo promedio de {date_string} anterior fue de {avg_value_vs} kWh y {date_string} seleccionado {avg_value} kWh." \
                    f"El consumo mÃ¡ximo de {date_string} anterior fue de {avg_value_vs} kWh y {date_string} seleccionado {avg_value} kWh." \
                    f"Solo debes emitir un mensaje de concienciaciÃ³n al alumnado. Si la difrencia es menor de +/-5% emite un mensaje neutro, si es un incremento superior a 5% emite un mensaje negaivo y si se reduce mÃ¡s de 5% uno positivo"
        else:
            prompt = f"No dispones de datos de {date_string} entorior. Solo analiza el consumo de {key_string} {selected_date.strftime('%d/%m/%Y')}. " \
                     f"El consumo total de {date_string} seleccionado es {total_value} kWh. El promedio es {avg_value} kWh y el mÃ¡ximo es {max_value} kWh a las {hora_max.strftime('%H:%M')}." \
                     f"Se conciso y claro."

        if st.button("Generar mensaje"):
            with st.chat_message("assistant"):
                st.markdown("Generando mensaje...")
            try:
                response = openai.chat.completions.create(
                    model=st.session_state["openai_model"],
                    messages=[
                        {"role": "system", "content": "Eres un asistente experto en anÃ¡lisis de consumo energÃ©tico."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=500
                )
                message = response.choices[0].message.content
                st.session_state.messages.append({"role": "assistant", "content": message})
                with st.chat_message("assistant"):
                    st.markdown(message)
            except Exception as e:
                st.error(f"Error al generar el mensaje: {e}")

# --- REFRESCO AUTOMÃTICO (en producciÃ³n) ---
time.sleep(3600)
st.rerun()
